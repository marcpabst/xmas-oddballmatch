# Methods and Materials
## Data Acquisition

### Participants

#### 100 ms Presentation Rate

Twenty-three psychology undergraduate students (2 males, average age 22.6 yrs., $SD=5.57$, range 18 - 42 yrs.) were recruited at the Institute of Psychology at the University of Leipzig. All participants reported good general health, normal hearing and had normal or corrected-to-normal vision. Written informed consent was obtained before the experiment. One-third (34.8%) of participants spent time enaging in musical activities at time of survey, while 8.7% had no prior experience in music training. Handedness was asseced using a modified version of the Edinburgh Handedness Inventory [@oldfieldAssessmentAnalysisHandedness1971, see appendix]. A majoritiy (00%) of parcicipants favored the right hand.  Particpants were blinded in respect to the purpose of the experiment and received course credit in compensation.

#### 150 ms Presentation Rate

Twenty healthy participants (0 males, average age 00.0 yrs., $SD=0.00$, range 00 - 00 yrs.) were recruited. Particpants gave informed consent and reported normal hearing and corrected or corrected-to-normal vision. All participants were naive regarding the purpose of the experiment and were compensated in cource credit or money. 00 participants (00%) had received musical training in the last 5 years before the experiment while 00 (00%) reported no musical experiance. In addition, participants reported if streaming occured during the presentation of the tones.

### Stimuli and Stimulis Delivery
![ Tones of two different frequencies (A=440 Hz, B=449 Hz) were presented in two blocked conditions: In the “predictable” condition (top half), tones followed a simple pattern in which a single B-tone followed four A-tones. Some designated B-tones were replaced by A-tones ("pattern deviants"). In the "random" condition (lower half), tones were presented in a pseudo-random fashion ()  ](figures/fig_tones.png)

Participants where seated in a comfortable chair in a sound-insulated cabin. The experimental setup was practically the same as the one used ny Sussman, but instead of reading a book, subjects were asked to focus their attention on a previously selected movie. Movies were presented with subtitles but without sound. Commercially available software (MATLAB R2014a; The MathWorks Inc, Natick, MA) in conjunction with the Psychophysics Toolbox extension
[version 3.0.12, @brainardPsychophysicsToolbox1997; @kleinerWhatNewPsychtoolbox32007] was used to control stimulus presentation. Stimuli consisted of pure sinusoidal tones with a duration of 50 ms (including a 10 ms cosine on/off ramp), presented isochronously at a stimulation onsets asynchrony (SOA) of 100 ms for study 1 and 150 ms for study 2. Overall, a total of 40 blocks containing a mixture of frequent 440 Hz tones (“A” tones) and infrequent 449 Hz tones ("B" tones) were delivered binaurally using Sennheiser HD-25-1 II headphones. In one half of the blocks, tones were presented in pseudo-random order (e.g. A-A-A-B-A-B-A}, "random" condition), while in the remaining  block tone presentation followed a simple pattern in which a five-tone-sequence of four frequent tones and one infrequent tone (i.e. A-A-A-A-B) was repeated cyclically ("predictable" condition). Block order was counterbalanced accross participants. The ratio of frequent and infrequent tones was 10% for both conditions. Within the predictable condition, 10% of designated (infrequent) B tones were replaced by A tones, resulting in sporadic five-tone sequences consisting solely of A tones (i.e. A-A-A-A-A), thus violating the predictability rule. To assure comparability of local histories between tones in both conditions, randomly arranged tones were interspersed with sequences mimicking aforementioned patterns from the predictable condition (B-A-A-A-A-B and B-A-A-A-A-A) in the random condition. A grand total of 2000 tones in study 1 and 4000 tones in study 2 were delivered to each participant. 

### Data Acquisition

Electrophysiological data was recorded from active silver-silver-chloride (*Ag*-*AgCl*) electrodes using an ActiveTwo amplifier system (BioSemi B.V., Amsterdam, The Netherlands). Acquisition was monitored online to ensure optimal data quality. A total of 39 channels were obtained using a 32-electrode-cap and 7 external electrodes. Scalp electrode locations conformed to the international 10–20 system. Horizontal and vertical eye movement was obtained using two bipolar configurations with electrodes placed around the lateral canthi of the eyes and above and below the right eye. Additionally,  electrodes were placed on the tip of the nose and at the left and right mastoid sites. Data was sampled at 512 Hz and on-line filtered at 1000 Hz.


## Analysis Pipeline

Data prepossessing was implemented using a custom pipeline based on the *MNE Python* software package [@gramfortMEGEEGData2013] using *Python 3.7*. All computations were carried out on a cluster operated by the University Computation Center of the University of Leipzig. Code used in thesis is publicly available at <https://github.com/marcpabst/xmas-oddballmatch>. 

First, EEG data was subjected to the ZapLine procedure [@decheveigneZapLineSimpleEffective2020] to remove line noise contamination. A fivefold detection procedure as described by @bigdely-shamloPREPPipelineStandardized2015 was then used to detect and subsequently interpolate bad channels. This specifically included the detection of channels thain contain prolonged segments with verry small values (i.e. flat channels), the exclusion of channels based on robust standard deviation (deviation criterion), unusualy pronounced high-frequency noise (noisiness criterion), and the removal of channels that were poorly predicted by nearby channels (correlation criterion and predictability criterion). Channels considered bad by one or more of these methods were removed and interpolated using spherical splines [@perrinSphericalSplinesScalp1989]. Electrode locations for interpolations were informed by the BESA Spherical Head Model.

For independant component anaylsis (ICA), a 1-Hz-high-pass filter (134th order hamming-windowed FIR) was applied prior to ICA [@winklerInfluenceHighpassFiltering2015]. To further reduce artifacts, Artifact Subspace Reconstruction [ASR, @mullenRealtimeNeuroimagingCognitive2015] was used to identify and remove parts of the data with unusual characteristics (bursts). ICA was then carried out using the *Picard* algorithm [@ablinFasterICAOrthogonal2017; @ablinFasterIndependentComponent2018] on PCA-whitened data. To avoid rank-deficiency when extracting components from data with one or more interpolated channels, PCA was also used for dimensionality reduction. The EEGLAB [version 2020.0, @delormeEEGLABOpenSource2004] software package and the IClabel plugin [version 1.2.6, @pion-tonachiniICLabelAutomatedElectroencephalographic2019] were used to automatically classify estimated components. Only components clearly classified (i.e. confidence above 50%) as resulting from either eye movement, muscular, or heartbeat activity were zeroed-out before applying the mixing matrix to unfiltered data.

In line with recommendations from @widmannDigitalFilterDesign2015 and @decheveigneFiltersWhenWhy2019, a ORDER finite impulse response (FIR) bandpass filter from 0.1 Hz to 40 Hz (Hamming window, 0.1 Hz lower bandwith, 4 Hz upper bandwidth, 0.0194 passband ripple, and 53 dB stopband attenuation). Continuous data was epoched into 400 ms long segments around stimulus onsets. Epochs included a 100 ms pre-stimulus interval. No baseline correction was applied. Segments exeeding a peak-to-peak voltage difference of  100 µV were removed. On average, NN epochs No data set meet the pre-registrated exclusion criterion stated of less than 100 trials per condition, thus data from all participants (20 for 100 ms presentation rate and 23 for 150 ms presentation rate) was analysed.

## Statistical Analysis

Statistical Analyis was carried out using the R programming language (version 3.2). Dependent variables quantifying missmatch negativity response were calculated by averaging amplitudes in a time window strechting ±25 ms around the maximum negativity obtained by subtracting the mean ERP timecourse following the A tones from the mean ERP following B tones. To compute mean amplitudes, ERPs to 4th position A tones (A-A-A-**A**-X, **boldface** indicates the tone of interest) and B tones (A-A-A-A-**B**) were averaged seperatly for both the *random* and the *predictable* *condition*. For the *random condition*, only tones that were part of a sequence matching the patterns in the *predictable* condition were included. 

In accordance with the original analysis by @sussmanOrganizationSequentialSounds2005, mean amplitudes for frontocentral electrodes (FZ, F3, F4, FC1, and FC2) and the two mastoid positions (M1 and M2) were averaged separately. Then, for both SOAs, independant three-way repeated measures analyses of variance with factors *condition* (factors *predcitable* and *random*), *stimulus type* (factors *A tone* and *B tone*), *electrode locations* (levels *fronto-central* and *mastoids*), and all possible interactions were calculated. Following this, significant interactions effects were further investigated using post-hoc *t*-tests.

Besides the fact that p-values are frequently misinterpreted [@hubbardWidespreadMisinterpretationPvalues2011], traditional null hypothesis testing fails to explicitly quantify evidence in favor of $\mathcal{H_0}$ [e.g. @aczelQuantifyingSupportNull2018; @meehlTheoreticalRisksTabular1978; @kirkPracticalSignificanceConcept1996; @goodmanDirtyDozenTwelve2008]. Similarly, p-values can exaggerate evidence against $\mathcal{H_0}$ [that is, observed data might be more likely under $\mathcal{H_0}$ than under $\mathcal{H_1}$ even tough $\mathcal{H_0}$ is rejected e.g., @hubbardWhyValuesAre2008; @rouderBayesianTestsAccepting2009; @wagenmakersBayesianInferencePsychology2018; @sellkeCalibrationValuesTesting2001] [^1].  Conversely, Bayesian hypothesis testing using Bayes factors  can provide an intuitive way to compare observed data's likelihood under the null hypothesis versus the alternative hypothesis [@wagenmakersPracticalSolutionPervasive2007]: $BF_{10} = \frac{Pr(data|\mathcal{H}_0)}{Pr(data|\mathcal{H}_1)}$. Here, this approach was applied in agreement with the concept described by @rouderBayesianTestsAccepting2009 as an alternative to classical frequentist paired *t*-tests. Folowing this notion, Bayes factors for within-participant differences $y_i$ were computed assuming $\mathcal{H_0}: y_i \sim Normal(0, \sigma^2)$ and $\mathcal{H_1}: y_i \sim Normal(\delta, \sigma^2)$; $\delta \sim Cauchy(0, 1/\sqrt{2})$. A Jeffreys prior was used for the variance $\sigma^2$ in both models:  $p(\sigma^2) \propto 1/\sigma^2$.  Calculations were performed using the Hamiltonian Monte Carlo method implemented in *Stan* [version 2.25, @carpenterStanProbabilisticProgramming2017].   

Finally, the relationship between epoch number and the reliability analysis was analyzed by drawing random subsamples of different sizes from both our data sets and calculating split-half reliability employing the Spearman-Brown approach. For this, single trial responses for all A and B tones in the predictable condition were randomly shuffled. Then, $100, 200, ..., N_{max}$  ($N_{max, 100ms} = 3000, N_{max, 150ms}=1500$) epoches were drawn, randomly assigned to one of two halfes, and afterwards averaged seperatly for bothtone types. Then, split-half realibility was calculated using the differences between A and B tones in the MMN latency window using the Sprearman-Brown prophecy formula[^2] [@brownEXPERIMENTALRESULTSCORRELATION1910; @spearmanCorrelationCalculatedFaulty1910]. This procedure was repeated 100 times for each $N$ and split-half-relaibilites thus obtained were subsequently averaged.

\newpage

[^1]: it doesn't quantify evidence in favor of the $H_1$, either

[^2]: as given by ${\rho}_{xx'} = \frac{2{\rho}_{12}}{1+{\rho}_{12}}$, where ${\rho_{12}}$ is the Pearson correlation coefficient between the two halfes. 






