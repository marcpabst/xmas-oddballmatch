\newpage

# Introduction

Unraveling the mysteries of human perception might be one of the most fascinating and difficult challenges in cognitive science. We usually have little regard for this, but at every single moment, we achieve something outstanding: By forming a coherent representation from the tangled mess of external stimuli that reach our sensory organs, we make sense of the outside world. In doing so and seemingly effortlessly, we overcome complicated mathematical and philosophical problems. Recent advances in emerging fields like computer vision and machine hearing have provided a sense of how daunting these tasks can be—requiring complex models that consume vast amounts of computational resources and energy. What enables the brain to fulfill these functions with such ease while consuming no more than the power equivalent of a lightbulb?  

Over the centuries, many theories have been broad forward in an attempt to answer these questions. While early philosophers like Aristotle believed in the idea of direct or naïve realism (the idea that the outside world is perceived directly), early modern scholars like John Locke promoted the concept of indirect realism, which is highly compatible with the assumption of representationalism in cognitive science (perceptual experiences result from an internal representation rather than directly from external objects). Among the first who developed a consistent theory defining the rules followed by indirect perception were the Gestalt psychologists of the early 20th century. Wertheimer, Koffka, and Köhler hypothesized that Gestalt principles, self-organizing rules on how individual elements should be grouped or separated, guide perception. Intriguingly, they based their principle on the observation that humans perceive a global whole instead of just collections of individual parts. 

Much later, auditory scientists faced the same challenges described in the first paragraph, but now in a very particular context: They were puzzled by the brain's ability to convert small air pressure fluctuations into actual auditory percepts. Somehow, the brain forms meaningful perceptual experiences from what can only be described as a busy mess of sound waves that originate from a plethora of different sources differing in pitch, loudness, and spatial position. Known as the *cocktail party effect* [@cherryExperimentsRecognitionSpeech1953], this problem was compared to inferring the positions, shapes, and movements of motorboats on a lake—just by observing how two nearby objects move up and down the waves. Attempts to find answers to this perplexing question lead to the development of auditory scene analysis (ASA). Not unlike the concepts proposed by the Gestalt theorists six decades earlier, @bregman1990auditory suggested that the brain uses so-called _streaming_ and _segregation_ to form auditory objects from rich spectro-temporal information. At its core, ASA relies on two different categories of grouping, namely *sequential* and *simultaneous* integration: Simultaneous integration (or vertical integration) refers to the grouping of concurrent properties into one or more separable auditory objects, a process informed by temporal cues like common onset and offset, spectral and spatial characteristics. Sequential integration (or horizontal integration), on the other hand, describes how temporally distinct sounds are merged into one or multiple coherently perceived streams (contrary to auditory objects in simultaneous grouping, only one such stream can be actively perceived at any time). While vertical and horizontal grouping can come to different and therefore competing results, sequential grouping often takes precedence over cues for simulations integration [@bendixenPredictabilityEffectsAuditory2014].

Often, the key to understanding such complex phenomena lies in learning about the most basic processing steps. In auditory research, these steps usually come in the shape of very simple stimuli, often consisting of nothing more than pure tones. Such stimuli were also the first to be used in the auditory oddball paradigm, a now well-established and robust paradigm extensively used in event-related potential (ERP) studies [@squiresTwoVarietiesLonglatency1975]. In its basic form, participants are presented with a series of similar tones or sounds (so-called *standard* events), interrupted by rare tones or sounds that differ in at least one feature (*deviant* events) from the more frequent ones. Strikingly,  deviant events elicit more extensive neural activity over sensory areas. This finding is known as the mismatch negativity (MMN) component because when measured using electroencephalography (EEG), a robust negative deflection can be observed in the difference wave obtained by subtracting the response to standard events from the response to deviant events. Negativity is strongest in the frontotemporal area of the scalp, with a peak latency ranging from 100 to 250 ms after stimulus onset. The MMN is not only elicited by individual rare deviant tones embedded in a stream of frequent tones but can also arise in the presence of complex rule violations, i.e. when abstract auditory regularities are violated [@paavilainenMismatchnegativityMMNComponent2013]. MMNs resulting from violations of regularities based on complex auditory regularities are referred to as _pattern MMN_ from hereon. Complex auditory regularities can come, for example, in the form of the direction of frequency changes in tone pairs [e.g., @saarinenRepresentationAbstractAttributes1992], infrequent shortenings of SOA [@fordEventRelatedPotentialsERPs1981], or rare breaks in an alternating sequence [@alainBrainIndicesAutomatic1994]. 

Interestingly, implications of observed MMN components are highly compatible with another prevalent theory of perception, namely the idea that perception is not exclusively a stimulus-driven bottom-up process but is informed by internal predictions. Despite their recent popularity, these ideas have been around for a long time and famously trace back to the physiologist Hermann von Helmholtz. Gregory's notion of "perception as hypotheses" is similarly well-known. Most recently, this notion has been introduced as a theory known as hierarchical predictive coding. Predictive coding specifically suggests that at every processing state, predictions from so-called *probabilistic generative models* and sensory input are compared continuously, and only their difference, termed *prediction error*, is propagated. MMN responses have been proposed as an index of prediction error [@wacongneEvidenceHierarchyPredictions2011]. Although other interpretations exist [e.g., @bregman1990auditory; @mayMismatchNegativityMMN2010], the MMN is frequently interpreted as a marker of expectation violations—a notion particularly emphasizing the role that predictions plays in perception [e.g., @winklerInterpretingMismatchNegativity2007].

An interesting situation arises when concurrent predictive clues exist. Following this idea, @sussmanPredictabilityStimulusDeviance1998 presented participants with a sequence of frequent pure tones and rare pitch deviants while reading a book of their choice. Tones were arranged in a predictable five-tone pattern consisting of four standard tones and one deviant (i.e., A-A-A-A-B-A-A-A-A-B, ''-'' indicating silence between the tones). ERPs to A and B tones were compared for rapid (SOA of 100 ms) and slow (SOA of 1300 ms) stimulation rates. The 100 ms SOA presentation also included a control condition in which tone order was pseudo-random (e.g., A-A-A-B-A-B-A-A-A) but without altering deviant occurrence probability ($Pr(B) = .20$). When the tone presentation order is random, only the relative occurrence frequency of tones carries value for predicting the next tone. This, we refer to as *proportional regularity*. However, in an ordered presentation, a sequence of four standard tones is always followed by one deviant tone. Thus, understanding this relationship should allow for *perfect prediction*  in which all deviant tones can be expected with absolute certainty. We call this regularity a *pattern regularity*. Provided the underlying mechanism can incorporate such information, the pitch deviants' processing should now correspond to that of standard tones, and therefore no MMN should be elicited.

Interestingly, in Sussman et al., MMNs were only elicited if tone presentation was slow and predictable or fast and random, but not when predictable tones were presented rapidly.  In a subsequent study, @sussmanOrganizationSequentialSounds2005 used the same pattern at different SOAs (200 ms, 400 ms, and 800 ms). Similar to their previous study, grouped presentation at 400 ms and 800 ms SOA elicited an MMN response, while no evidence for such a deflection was found at a stimulation rate of 200 ms. Sussman et al. attributed this observation to sensory memory limitations. That is, only when auditory memory can accommodate enough repetitions of the five-tone pattern can the brain integrate tones into a coherent representation allowing for accurate predictions of deviant tones. In turn, this would explain the absence of MMNs when the presentation was fast and ordered. They argued that while valid for fast presentation rates with SOAs up to 200 ms, for longer SOAs, pattern duration would be too long,  thus exceeding sensory memory capacity.

In a recent in-class replication study, @scharfPredictableChangesFastpacedinprep presented participants with the same stimuli as Sussmann et al. in a very similar experimental setting. Their study only differed in that participants were assigned a simple task in which they had to count visual targets instead of reading a book of their choice. Surprisingly, while descriptive results were compatible with Sussmann et al., pairwise comparisons revealed no significant effect when comparing deviant and standard tones for both the *random* and the *predictable* condition. Further Bayesian analysis remained largely inconclusive, providing only *anecdotal* evidence in favor of the aforementioned effect for *random* presentation and *moderate* evidence for its absence in the *predictable* condition. 

In the face of the replication crisis, many scientists have become painfully aware of the importance of replicability [@ioannidisWhyMostPublished2005]. Exact or quasi-exact replication studies that try to match the original study's experimental conditions as closely as possible are often regarded as the gold standard of science [@popperLogikForschungZur1935; @jasnyAgainAgainAgain2011]. However, replications that extend, change, or optimize materials or methods of the original work also offer valuable insight. This kind of replication is known as _conceptual_ [@schmidtShallWeReally2009] and refers to the usage of different methods to repeat the test of a hypothesis or experimental result. 

#### Hypothesis, Aims, and Objectives
This thesis seeks to replicate Sussman et al.'s findings. It mainly follows the procedure laid out by @sussmanOrganizationSequentialSounds2005. However, it extends the original design in some critical aspects. First, the aforementioned five-tone patterns are presented in both the _predictable_ condition and in the _random_ condition. That is, pseudo-random order will be deliberately broken by occasionally presenting (B-)A-A-A-A-B-patterns. In particular, this will ensure that the local history of B tones in the *random* condition is comparable to that in the *predictable* condition. Also, B tones are compared exclusively to their preceding A tones. Lastly, a small number of A-A-A-A-B-sequences will be replaced by A-A-A-A-A sequences in both conditions, allowing for the comparison of physically identical tones in different contexts. The advantage of this design is discussed in more detail in the following paragraphs. A pre-registration covering data collection, processing, and analysis is available at https://osf.io/cg2zd/. Deviations from this pre-specified plan and further exploratory analyses are explicitly reported.

@sussmanOrganizationSequentialSounds2005 interpretation of the original results suggests that at fast stimulation rates (SOAs of 200 ms and faster), extracted pattern-based regularities take precedence over proportion-based regularities. If this is true, B tones in the *predictable* condition should not be considered a *mismatch* and should not elicit an MMN response. In contrast, since there is no way to predict B tones in the _random_ condition reliably, these tones would still be considered _deviant_ events and are therefore expected to generate an MMN. On the other hand, when an A tone replaces a predictable B tone, one would expect an MMN, despite tones beeing physically identical as _pattern regularity_ is violated. 

Specifically, hypotheses are formulated in regards to the ERPs elicited by the fifth tone in the five-tone sequence (A-A-A-A-**B** or  A-A-A-A-**A**; boldface marks tone of interest) compared to the fourth tone in that sequence (A-A-A-**A**-X, "X" marking either an A or a B tone). Suppose Sussman's interpretation holds, one expects negativity in the N1/MMN time range (about 100-200 ms after tone onset) for deviations in the B-A-A-A-A-B-sequence in the *random* condition since B tones violate the *proportional regularity* within the local context. This kind of response will hereinafter be referred to as a *local MMN*. Besides, one expects no evidence for such an effect (or evidence favoring $\mathcal{H_0}$, i.e., that there is no effect) in the *predictable* context since more informative higher-order predictions based on *pattern regularity* are not violated. Since MMNs should only be observed in one of the conditions, MMNs responses should also differ between conditions. Lastly, the comparison between the 5th A tone and the proceeding A tone (A-A-A-**A**-X vs. A-A-A-A-**A**)  should be considered as a mismatch as the rare pattern (A-A-A-A-A) deviates from the more frequent pattern (A-A-A-A-B)  and is therefore expected to elicit a significant _pattern MMN_ response.

However, other results than those assumed by the original authors are conceivable. Here, two additional theoretical considerations that could explain divergent results will be briefly discussed. Of these, the first one is that the auditory system may not be able to extract complex patterns and therefore relies entirely on _proportional regularities_.  In this case, no *pattern regularity* is extracted, and B tones should result in a *local MMN* response regardless of presentation context since the predictive value of the _proportional regularity_ does not vary between conditions. Furthermore, this notion implies that local MMN responses would not differ between conditions. Similarly, when violating the pattern regularity by introducing rare A tones at the fifth place of the predictable sequence, no pattern MMN should be triggered since A tones do not constitute a mismatch under this premise. 

As a another possibility, the brain might use *proportional regularities* and *pattern regularities* concurrently, resulting in a _local MMN_ following B tones in either condition. Also, when violating the *pattern regularity* by presenting A tones at the fifth place, these tones should be detected as deviants and therefore result in a _pattern MMN_.