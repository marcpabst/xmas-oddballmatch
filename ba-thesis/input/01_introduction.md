\newpage
# Introduction

Unraveling the mysteries of human perception might be one of the most fascinating and difficult challenges in cognitive sciences. Mostly unnoticed and at every moment in our lives, we achieve something outstanding: By forming a coherent representation from the tangled mess of external stimuli that reach our senses, we make sense of the outside world. Seemingly effortlessly, in doing so we solve complicated mathematical problems such as the inverse problem. Recent advances in fields like computer vision and machine hearing have provided a sense of how daunting these tasks can be - requiring complex models consuming vast amounts of computational resources and energy. What enables the brain to fulfill these functions with such ease while consuming no more than a lightbulb's power equivalent?  

Overy the centruies, many theories have been broad forward attmepting to answer these qustions. Great philosophers like Plato, Kant and Locke had varyiing success in developing their own ideas on the inner workings of perception. Among the first who developed a consistent theory of the rules that perception follows, were the Gestalt psychologist of the early 20th century. Wertheimer, Koffka, and KÃ¼hler hypothesized that so-called Gestalt principles, rules on how indiivudal elements should be grosuped or seperated, would guide perception. Their conecpt was based on the the obersation that humans tend to perceive integrated patterns as opposed to just collection of individual elements. 

Much later, auditory scientists faced the same challenge described earlier, but now in a very speific context. They were puzzled: How does the brain form meanignful peceptual experiences from what can only be desribed as a busy mess of sound waves that originate from a myriad of different sources differing in pitch, loudness, and spatal position. Known as the *cocktail party effect*, this problem is often compared to inferring the posiitons, shapes and movements of boats on a lake - just by observing how two nearby objects move up and down on the waves. Attempts to find answers to this perplexing question lead to the development of auditory scene anaylsis (ASA). Not unlike the concepts proposed by the Gestalt theorists some decades earlier,  @Bregman suggested that the brain uses so-called _streaming_ and _segregation_ to form auditory objects from rich spectro-temporal infromation. Auditory scene analysis relies on two different categories of grouping, called sequential and simultaneous integration. Simultaneous or vertical integration refers to the grouping of concurent properties into one or more separable auditory objects, a process informed by temporal cues like common onset and offset, spectral and spatial characteristics among others. Sequential integration on the other hand describes how temporally distinct sounds are merged into one or multiple coherently perceived stream (contrary to simulatinous grouping, only one such stream can be activly perceived at any time). While vertical and horizontal grouping can come to different and therefore competing results [@needsref], sequential grouping often takes precedence over cues for simulatoius integration [@needsref],

As is so often the case, the key to understanding such complex phenomena seems to lie in learning about the most basic processing steps. In auditory research this steps usually come in the shape of simple stimuli, often consisting of nothing more than pure tones. The auditory oddball paradigm is a well-established and robust paradigm extensivly used in event related potential (ERP) studies. In its basic form, participants are presented with a series of similar tones or sounds (so-called *standard* events), interrupted by rare tones or sounds that differ in at least one feature (*deviant* events) from the more frequent ones. Strikingly, deviant events elicit larger neural activity over sensory areas - a finding that is known as the missmatch negativity (MMN) component, because when measured using EEG, a robust negative defelction can be observed obtained by subtracting the reponse to deviant events from the response to standard events. Negativity is strongest in the fronto-temporal area of the scalp with a peak latency ranging from 100 to 250 ms after stimulus onset. The eliction of MMN is not restricted to the reptition of physically identical stimuli but can also be observed when deviant events are of complex nature, e.g. when abstract auditory regularities are violated [@paavilainenMismatchnegativityMMNComponent2013]. The regularities can come in the form of relationships between two [@saarinenRepresentationAbstractAttributes1992] or multiple tones [@nordbyEventRelatedPotentialsBreaks1988; @schrogerPreattentivePeriodicityDetection1996; @alainBrainIndicesAutomatic1994]. Interestingly, this finding is also higly compatible with another prevalent theory of perception: The idea that prediction informs how humans percive the world. These kind of ideas have been around a long time and famously trace back to the remarkable physiologist Hermann von Helmholtz. In its most recent iteration, this theroy has been kown as (hirachical) predictive coding. These theories vary in how much reltive weight they assign to bottom-up processing and prediciton. But regardless of how one might interpret this relaton, the observation of MMN almost inevitably leads to an interpretation in which the processing of deviant signals can be reagrded as a violation of expectation. As such, these these error signals play an important role in understanding prediction, expectation and perception in the human brain. 

But how does the brain handle situations in which concuretn but contradictory predictive clues exist? Follwing this idea, @sussmanPredictabilityStimulusDeviance1998 presented participants with a sequency of frequent pure tones and rare pitch deviants while reading a book of their choice. Tones were arranged in a predictable five-tone pattern consisting of four standard tones and one deviant (i.e. A-A-A-A-B-A-A-A-A-B, ''-'' indicating silence between the tones). ERPs to A and B tones were compared for rapid (SOA of 100 ms) and slow (SOA of 1200 ms) stimulation rates. For the 100 ms SOA, they also included a control condition in which tone order was pseudo-random (e.g. A-A-A-B-A-B-A-A-A) without altering deviant probability ($p_B = 20\%$). When tones are presented randomly, only their relative frequency of occurance carries value for predicting the pitch of the next tone. This, we refer to as *proportional regularity*. In an ordered presentation however, a sequence of four standard tones is alsways followed by a deviant tone. Thus, understanding this relationship should allow for *perfect* precition in which all deviant tones are expected with near-absolute certainty. We call this regularity a *pattern regularity*. Provided the underlaying mechanism can incooperate such information, the processing of the pitch deviants should correspond with that of standard tones and therefore no MMN would be elicted. Interestingly, in the case of Sussman et al., MMNs were only elicted if tone presentation was slow and predcitable or fast and random, but not when precitable tones were presented in a rapid fashion.  In a subsequent study, @sussmanOrganizationSequentialSounds2005 used the same pattern at different SOAs (200 ms, 400 ms, and 800 ms). Simmilarly to their prevous study, ordered presentation at 400 ms and 800 ms SOA elicted an MMN response, while at a stimulution rate of 200 ms evidence for such a deflection was absent. Sussman et al. attributed this observation to sensory memory limitations. That is, only when auditory memory can accommodate enough repetitions of the five-tone pattern, tones could  be integrated into a coherent representation allowing for accurate predictions of deviant tones. This, in turn, would explain the absence of MMNs in the fast presentation condition. Based on this, they argued that while true for fast presentation rates with SOAs up to 200 ms, for longer SOAs pattern durations would be too long and thus representatations would eceed sensory memory capacity. 

In a recent in-class replication study, @scharfPredictableChangesFastpacedinprep presented participants with the same stimuli as Sussmann in a verry simmilar expeirmatnal setting. Their study only differed in that participants were given a simple task in whick they had to count visual targets instead of reading a book of their choice. Surprisingly, while descriptive results were compatible with those of Sussmann et al., pairwise comparison revealaed no significant effect when comparing deviant and standard tones fot both the *random* and the *predeictable* condition. Further Bayesian analysis remained largely inconclusive, providing only *andecdotal* evidece in favor of such an effect for *random* presentation and *moderate* evidence for its absence in the *predictable* condition. In the face of the replication crisis, many scientists have become painfully aware of the importance of replicability. It is clear that exact or quasi-exact replication studies that try to match experimental conditions of the original study as closely as possible are one kay to more reliable reasearch results [@popperLogikForschungZur1935]. However, replications that extend, change or optimize materials or methods of the original work also offer valuable insight. These forms of replications are know as conceptal [@schmidtShallWeReally2009] and reffer to the use of different methods to repeat the test of a hypothesis or experimental result. 

## Design and Hypothesises

In this thesis, we try to answer the verry same question Sussman et al. posed: When first-order as well as higher-order relationships between auditory events can offer concurent but varying degrees of predcitve value, what information is used? We largly follow the procure layed out by @sussmanOrganizationSequentialSounds2005 though we deviate in some important aspects First, afforementioned five-tone patterns are not only presented in the *preictable* condition, but also in the *random* context. That is, pseudo-random order will be deberatly broken by occasionally presenting B-A-A-A-A-B-patterns. In particular, this will make sure that the local history of B-tones in the *random* condition is comparable to that in the *predictable* condition. Secondly, B tones are compared exclusively with their preceding A tones. And lastly, a small number of A-A-A-A-B will be replaced by A-A-A-A-A sequences. The expected advantages of this design are discussed in more detail in the hypothesis section. A pre-registration coverng data collection, processing, and anaylis is avaible at https://osf.io/cg2zd/. Deviations from this pre-specified plan and further, exploratory analysisi will be clearly marked.

@sussmanOrganizationSequentialSounds2005 intepretation of the original results would suggests that at fast stimultion rates, pattern-based regulairites take precedence over proportion-based regularites. If this is indeed the case, B-tones in the *predictable* condtiion should not be considered a *missmatch* and thus should not elict an MMN. In contrast, since there is no way to reliably predict B-tones in the *random* condition, these tones would be still considered as *deviant* events and are therefore expcected to generate a MMN. 

Specifically, the hypotheses are concerned with the ERPs elicted by the 5th tone in the five-tone sequence (A-A-A-A-**B** or  A-A-A-A-**A**)  compared to the 4th tone in that sequence (A-A-A-**A**-X, "X" marking either an A or an B tone). 

We will also compare the repective difference waves (A-A-A-A-**B** vs. A-A-A-**A**-B) in the *precitable* condition with that in the *random* condition.

In summary, i) one expects negativity in the N1/MMN time domain (about 100-200 ms after the beginning of the tone) for deviations in the BAAAA*B* sequence in the *random* condition, since B tones violate the *proportioanl regularity*, ii) one expects no evidence for such an effect (or evidence favoring $\mathcal{H_0}$ i.e. that there is no effect) in the *predictable* context since more informative higher-order predictions based on *pattern regularity* are not violated, and iii) the difference waves should differ significantly. If however no *pattern regularity* is extracted, B-tones should concotenly exlivt an MMN regardless of presentation context since the predictive value of the *proportional regularity* does not differ between conditions. In that case, difference waves should not differ. As a third possiblity, the brain might use *proportional regularities*and *pattern regularities* concurently, resulting in a negativity following B-tones in either condition. To further differentiate between these explainations, we also expect the comparison of 5th A tones to peceedin A tones (A-A-A-**A**-X vs. A-A-A-A-**A**)  to elict a  significant MMN for options i and iii, but not for option ii.

\newpage