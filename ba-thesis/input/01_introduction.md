\newpage
# Introduction

– Introducing oddball paradigm --
The auditory oddball paradigm is well-established type of experimental designs extensivly used in event related potential (ERP) studies. In the most basic form of this paradigm, subjects are presented with a series of similar tones or sounds (so-called *standards*), interrupted by rare tones or sounds that differ in at least one feature (*deviants*) from the more frequent ones. Since it is assumed that the brain constantly makes predictions about future sensory impressions and deviating auditory events must violate these predictions, these rare sounds play an important role in understanding prediction and expectation in the human brain. Different measures have been used to quantify differenced in processing between *standard* and *deviant* events,  
– introducing MMN --
One of the best-studied approaches to measure these differences in processing is known as the missmatch negativity (MMN) component, obtained by subtracting the reponse to deviant events from the resposne to standard events. Negativity is strongest in the fronto-temporal area of the scalp with a peak latency ranging from 100 to 250 ms after stimulus onset The eliction MMN is not restricted to the reptition of physically identical stimuli but can also be observed when deviant events are of complex nature, e.g. when abstract auditory regularities are violated [@paavilainenMismatchnegativityMMNComponent2013a]. The regularities can come in the form of relationships between two @saarinenRepresentationAbstractAttributes1992 or multiple tones [@nordbyEventRelatedPotentialsBreaks1988; @schrogerPreattentivePeriodicityDetection1996; @alainBrainIndicesAutomatic1994] a 

– introducing sussmans study --
@sussmanPredictabilityStimulusDeviance1998 presented participants with a sequency of frequent pure tones and rare pitch deviants. Tones were arranged in a predictable five-tone pattern consisting of four standard tones and one deviant (i.e. A-A-A-A-B-A-A-A-A-B, ''-'' indicating silence between the tones). ERPs to A and B tones were compared for rapid (SOA of 100 ms) and slow (SOA of 1200 ms) stimulation rates. For the 100 ms SOA, they also included a control condition in which tone order was pseudo-random (e.g. A-A-A-B-A-B-A-A-A) without altering deviant probability ($p_B = 20\%$).  MMNs were only elicted if tone presentation was slow and predcitable or fast and random. In a subsquent study, @sussmanOrganizationSequentialSounds2005 used the same pattern at different SOAs (200 ms, 400 ms, and 800 ms). Simmilarly to their prevous study, grouped presentation at 400 ms and 800 ms SOA elicted a MMN, while at a stimulution rate of 200 ms such evidence was absent. Sussman et al. attributed this observation to sensory memory limitations. Only when auditory memory accommodates enough repetitions of the five-tone pattern, tones could  be integrated into a coherent representation allowing for accurate predictions of deviant tones (explaing the absence of MMNs. They further argued that while this must be the case for fast presentation rates with SOAs up to 200 ms, for longer SOAs pattern durations would be too long ans thus eceed sensory memory capacity. The main weakness in their study is that they ma

– scharf muller --
In a recent in-class replication study, @scharfPredictableChangesFastpacedinprep. found that
 