\newpage
# Introduction

Unraveling the mysteries of human perception might be one of the most fascinating and difficult challenges in cognitive sciences. We usually have little regard for this, but at every single moment, we achieve something outstanding: By forming a coherent representation from the tangled mess of external stimuli that reach our sensory organs, we make sense of the outside world. In doing so and seemingly effortlessly, we overcome complicated mathematical and philosophical problems. Recent advances in emerging fields like computer vision and machine hearing have provided a sense of how daunting these tasks can be—requiring complex models that consume vast amounts of computational resources and energy. What enables the brain to fulfill these functions with such ease while consuming no more than the power equivalent of a lightbulb?  

Over the centuries, many theories have been broad forward in an attempt to answer these questions. While early philosophers like Aristotle believed in the idea of direct or naïve realism (the idea that the outside world is perceived directly), early modern scholars like John Locke promoted the concept of indirect realism, which is highly compatible with the assumption of representationalism in cognitive science (perceptual experiences result from an internal representation rather than directly from external objects). Among the first who developed a consistent theory defining the rules followed by indirect perception were the Gestalt psychologists of the early 20th century. Wertheimer, Koffka, and Köhler hypothesized that Gestalt principles, self-organizing rules on how individual elements should be grouped or separated, guide perception. They based their principle on the observation that humans perceive a global whole instead of just collections of individual parts. 

Much later, auditory scientists faced the same challenges described in the first paragraph, but now in a very particular context: They were puzzled by the brain's ability to convert small air pressure fluctuations into actual auditory percepts. Somehow, the brain forms meaningful perceptual experiences from what can only be described as a busy mess of sound waves that originate from a plethora of different sources differing in pitch, loudness, and spatial position. Known as the *cocktail party effect* [@cherryExperimentsRecognitionSpeech1953], this problem was compared to inferring the positions, shapes, and movements of motorboats on a lake—just by observing how two nearby objects move up and down the waves. Attempts to find answers to this perplexing question lead to the development of auditory scene analysis (ASA). Not unlike the concepts proposed by the Gestalt theorists six decades earlier, @bregman1990auditory suggested that the brain uses so-called _streaming_ and _segregation_ to form auditory objects from rich spectro-temporal information. At its core, ASA relies on two different categories of grouping, namely *sequential* and *simultaneous* integration: Simultaneous integration (or vertical integration) refers to the grouping of concurrent properties into one or more separable auditory objects, a process informed by temporal cues like common onset and offset, spectral and spatial characteristics. Sequential integration (or horizontal integration), on the other hand, describes how temporally distinct sounds are merged into one or multiple coherently perceived streams (contrary to auditory objects in simultaneous grouping, only one such stream can be actively perceived at any time). While vertical and horizontal grouping can come to different and therefore competing results, sequential grouping often takes precedence over cues for simulations integration [@bendixenPredictabilityEffectsAuditory2014]

Often, the key to understanding such complex phenomena seems to lie in learning about the most basic processing steps. In auditory research, these steps usually come in the shape of very simple stimuli, often consisting of nothing more than pure tones. Such stimuli were also the first to be used in the auditory oddball paradigm, a now well-established and robust paradigm extensively used in event-related potential (ERP) studies [@squiresTwoVarietiesLonglatency1975]. In its basic form, participants are presented with a series of similar tones or sounds (so-called *standard* events), interrupted by rare tones or sounds that differ in at least one feature (*deviant* events) from the more frequent ones. Strikingly,  deviant events elicit more extensive neural activity over sensory areas. This finding is known as the mismatch negativity (MMN) component because when measured using electroencephalography (EEG), a robust negative deflection can be observed in the difference wave obtained by subtracting the response to standard events from the response to deviant events. Negativity is strongest in the frontotemporal area of the scalp, with a peak latency ranging from 100 to 250 ms after stimulus onset. The elicitation of an MMN is not restricted to the repetition of physically identical stimuli but can also be observed when deviant events are complex, e.g., when abstract auditory regularities are violated [@paavilainenMismatchnegativityMMNComponent2013]. The regularities can come in the form of relationships between two [@saarinenRepresentationAbstractAttributes1992] or multiple tones [@nordbyEventRelatedPotentialsBreaks1988; @schrogerPreattentivePeriodicityDetection1996; @alainBrainIndicesAutomatic1994]. 

Interestingly, implications from MMN components are highly compatible with another prevalent theory of perception, namely the idea that perception is not (only) a stimulus-driven bottom-up process, but is informed by internal predicitons of some kind. In spite of their recent popularity, ideas of this nature have been around a long time and famously trace back to the physiologist Hermann von Helmholtz. Gregory's "perceptions as hypotheses"-sentiment is simmilarly well-known. Most recently, this notion has been introduced in a theory knows as (hierarchical) predictive coding. Predictive coding specifically suggests that at every processing state, predictions from so-called *probabilistic generative models* and sensory input are compared continuously, and only their difference, termed *prediction error*, is propagated. MMN responses have been proposed as an index of prediction error [@wacongneEvidenceHierarchyPredictions2011]. Although other interpretations exist [e.g., @mayMismatchNegativityMMN2010], the MMN is frequently interpreted as a marker of expectation violations—a notion particularly emphasising the role that predicitons plays in perception [e.g., @winklerInterpretingMismatchNegativity2007].

An interesting situation arises when concurrent predictive clues exist. Following this idea, @sussmanPredictabilityStimulusDeviance1998 presented participants with a sequence of frequent pure tones and rare pitch deviants while reading a book of their choice. Tones were arranged in a predictable five-tone pattern consisting of four standard tones and one deviant (i.e., A-A-A-A-B-A-A-A-A-B, ''-'' indicating silence between the tones). ERPs to A and B tones were compared for rapid (SOA of 100 ms) and slow (SOA of 1300 ms) stimulation rates. The 100 ms SOA condition also included a control condition in which tone order was pseudo-randomized (e.g., A-A-A-B-A-B-A-A-A) without altering deviant probability ($p_B = .20$). When tones are presented randomly, only their relative frequency of occurrence carries value for predicting the pitch of the next tone. This, we refer to as *proportional regularity*. However, in an ordered presentation, a sequence of four standard tones is always followed by one deviant tone. Thus, understanding this relationship should allow for *perfect prediction*  in which all deviant tones are expected with near-absolute certainty. We call this regularity a *pattern regularity*. Provided the underlying mechanism can incorporate such information, the processing of the pitch deviants should correspond with that of standard tones, and therefore no MMN would be elicited. Interestingly, in the case of Sussman et al., MMNs were only elicited if tone presentation was slow and predictable or fast and random, but not when predictable tones were presented rapidly.  In a subsequent study, @sussmanOrganizationSequentialSounds2005 used the same pattern at different SOAs (200 ms, 400 ms, and 800 ms). Similar to their previous study, grouped presentation at 400 ms and 800 ms SOA elicited an MMN response, while at a stimulation rate of 200 ms, evidence for such a deflection was absent. Sussman et al. attributed this observation to sensory memory limitations. That is, only when auditory memory can accommodate enough repetitions of the five-tone pattern; the brain can integrate tones into a coherent representation allowing for accurate predictions of deviant tones. This, in turn, would explain the absence of MMNs in the fast presentation condition. Based on this, they argued that while true for fast presentation rates with SOAs up to 200 ms, for longer SOAs, pattern durations would be too long, and thus representations would exceed sensory memory capacity.

In a recent in-class replication study, @scharfPredictableChangesFastpacedinprep presented participants with the same stimuli as Sussmann in a very similar experimental setting. Their study only differed in that participants were given a simple task in which they had to count visual targets instead of reading a book of their choice. Surprisingly, while descriptive results were compatible with those of Sussmann et al., pairwise comparisons revealed no significant effect when comparing deviant and standard tones for both the *random* and the *predictable* condition. Further Bayesian analysis remained largely inconclusive, providing only *anecdotal* evidence in favor of such an effect for *random* presentation and *moderate* evidence for its absence in the *predictable* condition. In the face of the replication crisis, many scientists have become painfully aware of the importance of replicability [@ioannidisWhyMostPublished2005]. Exact or quasi-exact replication studies that try to match the original study's experimental conditions as closely as possible are regarded as the gold standard of science [@popperLogikForschungZur1935; @jasnyAgainAgainAgain2011]. However, replications that extend, change, or optimize materials or methods of the original work also offer valuable insight. This kind of replication is known as conceptual [@schmidtShallWeReally2009] and refers to using of different methods to repeat the test of a hypothesis or experimental result. 

This thesis seeks to replicate the findings by Sussman et al. It largely follows the procure laid out by @sussmanOrganizationSequentialSounds2005. However, it deviates from the original design in some critical aspects.First, the aforementioned five-tone patterns are presented in both the _predictable_ condition and in the _random_ context. That is, pseudo-random order will be deliberately broken by occasionally presenting B-A-A-A-A-B-patterns. In particular, this will ensure that the local history of B-tones in the *random* condition is comparable to that in the *predictable* condition. Secondly, B tones are compared exclusively with their preceding A tones. Lastly, a small number of A-A-A-A-B will be replaced by A-A-A-A-A sequences in both conditions, allowing the comparison of physically identical tones in different contexts. The advantages of this design are discussed in more detail in the following paragraphs. A pre-registration covering data collection, processing, and analysis is available at https://osf.io/cg2zd/. Deviations from this pre-specified plan and further exploratory analyses are explicitly reported.

@sussmanOrganizationSequentialSounds2005 interpretation of the original results suggests that at fast stimulation rates (200 ms and faster), pattern-based regularities take precedence over proportion-based regularities. If this is indeed true, B-tones in the *predictable* condition should not be considered a *mismatch* and thus should not elict an MMN response. In contrast, since there is no way to reliably predict B-tones in the _random_ condition, these tones would still be considered _deviant_ events and are therefore expected to generate an MMN. On the other hand, when an A tone replaces a predictable B tone, one would expect an MMN, despite tones are physically identical. Specifically, hypotheses are formulated in regards to the ERPs elicited by the 5th tone in the five-tone sequence (A-A-A-A-**B** or  A-A-A-A-**A**; boldface marks tone of interest) compared to the 4th tone in that sequence (A-A-A-**A**-X, "X" marking either an A or an B tone). Hypotheses can be summarized as follows:

#### Pattern regularities
If Sussman's intepreation holds, one expects i) negativity in the N1/MMN time domain (about 100-200 ms after tone onset) for deviations in the BAAAA*B* sequence in the *random* condition, since B tones violate the *proportional regularity*, ii) one expects no evidence for such an effect (or evidence favoring $\mathcal{H_0}$ i.e., that there is no effect) in the *predictable* context since more informative higher-order predictions based on *pattern regularity* are not violated, and iii) the difference waves should differ significantly. Also,  the comparison between the 5th A tone and the proceeding A tone (A-A-A-**A**-X vs. A-A-A-A-**A**)  should be consiered a *mismatch* and is therefore expected to elicit a significant MMN response.

#### Proportional regularities
If, however, no *pattern regularity* is extracted, B-tones should continuously result in an MMN regardless of presentation context since the predictive value of the _proportional regularity_ does not differ between conditions.  When prsenting A tones at the 5th position, no MMN should occur. Also, difference waves should not differ. 

#### Pattern regularities and proportional regularities
As a third possibility, the brain might use *proportional regularities* and *pattern regularities* concurrently, resulting in negativity following B-tones in either condition. Fifth-posiiton A tones should consitute an expectation violation and should therefore results in a negative deflection.


\newpage