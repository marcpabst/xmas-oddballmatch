# Methods and Materials

### Participants

All participants were recruited at the Institute of Psychology at the University of Leipzig and reported good general health, normal hearing, and had a normal or corrected-to-normal vision. Written informed consent was obtained before the experiment. Participants were blinded to the purpose of the experiment and were compensated in course credit or money.

#### 100 ms Presentation Rate
Data were collected from twenty participants (2 males, average age 22.3 yrs., $SD=6.46$, range 18 - 41 yrs.). 

#### 150 ms Presentation Rate
The sample consisted of twenty-three psychology undergraduate students (2 males, average age 22.6 yrs., $SD=5.57$, range 18 - 42). 


### Procedure and Stimuli
![ Caption  ](figures/fig_tones.png)

Participants sat in a comfortable chair in a sound-insulated chamber. The experimental setup was practically identical to that of Sussman et al.; however, instead of reading a book, subjects were asked to direct their attention to a self-selected movie. Movies were presented with subtitles but without sound. Commercially available software (MATLAB R2014a; The MathWorks Inc, Natick, MA) in conjunction with the Psychophysics Toolbox extension
[version 3.0.12, @brainardPsychophysicsToolbox1997; @kleinerWhatNewPsychtoolbox32007] was used to control stimulus presentation. Stimuli consisted of pure sinusoidal tones with a duration of 50 ms (including a 10 ms cosine on/off ramp), presented isochronously at a stimulation onsets asynchrony (SOA) of 100 ms and 150 ms, respectively. Blocks contained 820 frequent 440 Hz tones ("A" tones) and 120 infrequent 449 Hz tones ("B" tones), delivered binaurally using Sennheiser HD-25-1 II headphones at 70 dB. For the 100 ms condition, participants were presented with 40 blocks (100 s duration each), while 20 blocks (150 s duration) were presented in the 150 ms condition. In one-half of the blocks, tones occurred in pseudo-random order (e.g., A-A-A-B-A-B-A}, *random* condition) while in the other half, tone presentation followed a simple pattern in which a five-tone-sequence of four frequent tones and one infrequent tone (i.e., A-A-A-A-B) was repeated cyclically (*predictable* condition). Block order was counterbalanced across participants.  Additionally, A tones replaced 10% of designated (infrequent) B tones, resulting in sporadic five-tone sequences consisting solely of A tones (i.e., A-A-A-A-A), thus violating the *pattern regularity*.  Care was taken that sequences in the *random condition* were always sepearated by at least five pseudo-random tones and that A-A-A-A-A-patterns were always seperated by at least two A-A-A-A-B-patterns. To assure comparability of local histories between tones of interest in both conditions, pseudo-randomly arranged tones were interspersed with sequences matching those from the predictable condition (B-A-A-A-A-B and B-A-A-A-A-A). A total of 2000 tones at 150 ms SOA or 4000 tones at 100 ms SOA were delivered to each participant.

### Data Acquisition

Electrophysiological data were recorded from active silver-silver-chloride (*Ag*-*AgCl*) electrodes using an ActiveTwo amplifier system (BioSemi B.V., Amsterdam, The Netherlands). A total of 39 channels were obtained using a 32-electrode-cap and seven external electrodes. Scalp electrode locations conformed to the international 10–20 system. Horizontal and vertical eye movement was obtained using two bipolar configurations with electrodes placed around the lateral canthi of the eyes as well as above and below the right eye. Additionally, three electrodes were placed on the tip of the nose and at the left and right mastoid sites. Data were sampled at 512 Hz and on-line low-pass filtered at 1000 Hz.


### Analysis Pipeline

Data prepossessing was implemented using a custom pipeline based on the *MNE Python* software package [@gramfortMEGEEGData2013] using *Python 3.7*. All computations were carried out on a cluster operated by the University Computation Center of the University of Leipzig. Code used in this thesis is publicly available at <https://github.com/marcpabst/xmas-oddballmatch>. 

First, EEG data were subjected to the ZapLine procedure [@decheveigneZapLineSimpleEffective2020] to remove line noise contamination. A fivefold detection procedure, as described by @bigdely-shamloPREPPipelineStandardized2015 was then used to detect and subsequently interpolate bad channels. Namely, this included detecting channels that contained prolonged segments with very small values (i.e., flat channels), the exclusion of channels based on robust standard deviation (deviation criterion), unusually pronounced high-frequency noise (noisiness criterion), and the removal of channels that were poorly predicted by nearby channels (correlation criterion and predictability criterion). Channels considered bad by one or more of these methods were removed and interpolated using spherical splines [@perrinSphericalSplinesScalp1989]. Electrode locations for interpolations were informed by the BESA Spherical Head Model.

For independent component analysis (ICA), a 1-Hz-high-pass filter (134th order hamming-windowed FIR) was applied [@winklerInfluenceHighpassFiltering2015]. Artifact Subspace Reconstruction [ASR, @mullenRealtimeNeuroimagingCognitive2015] was used to identify and remove parts of the data with unusual noise characteristics (bursts). ICA was then carried out using the *Picard* algorithm [@ablinFasterICAOrthogonal2017; @ablinFasterIndependentComponent2018] on principal-component-analysis--whitened (PCA) data. PCA was also used for dimensionality reduction to avoid rank-deficiency when extracting components from data with one or more interpolated channels. The EEGLAB [version 2020.0, @delormeEEGLABOpenSource2004] software package and the IClabel plugin [version 1.2.6, @pion-tonachiniICLabelAutomatedElectroencephalographic2019] were used to classify estimated components automatically. Only components clearly classified (i.e., confidence above 50%) resulting from either eye movement, muscular, or heartbeat activity were zeroed-out before applying the mixing matrix to unfiltered data. It should be noted that this procedure deviated from the pre-registration in that it was fully automated.

In line with recommendations from @widmannDigitalFilterDesign2015 and @decheveigneFiltersWhenWhy2019, a finite impulse response (FIR) bandpass filter from 0.1 Hz to 40 Hz (Hamming window, 0.1 Hz lower bandwidth, 5 Hz upper bandwidth, 0.0194 passband ripple, and 53 dB stopband attenuation). Continuous data were epoched into 400 ms long segments around stimulus onsets, including a 100 ms pre-stimulus interval. No baseline correction was applied, and segments exceeding a peak-to-peak voltage difference of  100 µV were removed. On average, 45 epochs were dopped. No dataset met the pre-registered exclusion criterion of less than 100 valid trials per condition; thus, data from all participants (20 for 100 ms presentation rate and 23 for 150 ms presentation rate) were analyzed.

### Statistical Analysis

Statistical analysis was carried out using the *R* programming language (version 3.2, The R Core Team) using the *rstatix* package [version 2.0, @kassambaraRstatixPipefriendlyFramework2020]. 

Calculation of the dependant variable followed the original study's procedure in averaging amplitudes in a time window extending ±25 ms around the expected peak of negativity. Specifically, this peak was obtained by subtracting the average ERP following the A tones from the average ERP following B tones in the *random condition* for both presentation rates seperatly. To compute mean amplitudes, ERPs to 4th position A tones (A-A-A-**A**-X, **boldface** indicates the tone of interest) and B tones (A-A-A-A-**B**) were averaged separately for both the *random* and the *predictable* *condition*. For the *random condition*, only tones presented as part of a sequence matching the patterns from the *predictable* condition were included in the analysis. 

In accordance with the original analysis by @sussmanOrganizationSequentialSounds2005, mean amplitudes for frontocentral electrodes (pooled FZ, F3, F4, FC1, and FC2) and the two mastoid positions (pooled M1 and M2) were averaged separately. Then, for both SOAs, independent two-way repeated-measures analyses of variance (ANOVA) with factors *condition* (levels *predictable* and *random*), *stimulus type* (levels *A tone* and *B tone*), *electrode locations* (levels *frontocentral* and *mastoids*), and all possible interactions were calculated. Following this, significant interaction effects were further investigated using post-hoc *t*-tests.

Going beyond the original study and extending the pre-registered procedure, Bayesian analysis was conducted for ANOVA posthoc comparisons. As mentioned above, traditional null hypothesis testing has some limitations that are often overlooked, leading to incorrect conclusions drawn from results. For example, not rejecting the null hypothesis can usually not be interpreted as evidence in favor of $\mathcal{H_0}$ [e.g., @aczelQuantifyingSupportNull2018; @meehlTheoreticalRisksTabular1978; @kirkPracticalSignificanceConcept1996; @goodmanDirtyDozenTwelve2008]. Similarly, p-values might exaggerate evidence against $\mathcal{H_0}$ [that is, observed data might be more likely under $\mathcal{H_0}$ than under $\mathcal{H_1}$ even tough $\mathcal{H_0}$ is rejected, e.g., @hubbardWhyValuesAre2008; @rouderBayesianTestsAccepting2009; @wagenmakersBayesianInferencePsychology2018; @sellkeCalibrationValuesTesting2001].  Conversely, Bayesian hypothesis testing using Bayes factors can provide an intuitive way to compare observed data's likelihood under the null hypothesis versus the alternative hypothesis [@wagenmakersPracticalSolutionPervasive2007], thereby making it possible to evaluate the null hypothesis as well: $BF_{10} = \frac{Pr(data|\mathcal{H}_0)}{Pr(data|\mathcal{H}_1)}$. Here, this approach was applied in agreement with the concept described by @rouderBayesianTestsAccepting2009 as an alternative to classical frequentist paired *t*-tests. Following this sentiment, Bayes factors for within-participant differences $y_i$ were computed assuming $\mathcal{H_0}: y_i \sim Normal(0, \sigma^2)$ and $\mathcal{H_1}: y_i \sim Normal(\delta, \sigma^2)$; $\delta \sim Cauchy(0, 1/\sqrt{2})$. A Jeffreys prior was used for the variance $\sigma^2$ in both models:  $p(\sigma^2) \propto 1/\sigma^2$.  Calculations were performed using the Hamiltonian Monte Carlo method implemented in *Stan* [version 2.25, @carpenterStanProbabilisticProgramming2017] and *RStan* [@standevelopmentteamRStanInterfaceStan2020]. 

Finally, the relationship between epoch number and the reliability analysis was analyzed by drawing random subsamples of different sizes from both data sets and calculating split-half reliability employing the Spearman–Brown approach. Thus, single-trial responses for all A and B tones in the predictable condition were randomly shuffled. Then, $100, 200, ..., N_{max}$  ($N_{max, 100ms} = 3000, N_{max, 150ms}=1500$) epochs were drawn, randomly assigned to one of two halves, and averaged separately for A and B tones. Then, split-half reliability was calculated using the differences between A and B tones in the MMN latency window using the Spearman–Brown prophecy formula[^2] [@brownEXPERIMENTALRESULTSCORRELATION1910; @spearmanCorrelationCalculatedFaulty1910]. This procedure was repeated 100 times for each $N$, and split-half-reliabilities obtained were subsequently averaged.

\newpage

[^2]: as given by ${\rho}_{xx'} = \frac{2{\rho}_{12}}{1+{\rho}_{12}}$, where ${\rho_{12}}$ is the Pearson correlation coefficient between the two halfes. 






