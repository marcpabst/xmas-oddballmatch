How are these mere eletrical signals processsed, combines and finally formed into meanignful peceptual experiences? While similar questions in the visual domain have intrigued scientists for a very long time and most notably lead to the emegence of the Gestalt psychology in the early 20th century, long before the term auditory scene analysis was coined. While the Gestalt psychologists formulated very abstract rules, which in their own view should not be limited to the visual domain but rather represent universal laws of human perception, their research was almost exclusivly carried out in the field of visual perception. Mainstream auditory perception science was largly engaged in how very basic features of sound would connect to perception. Particularly the works of A. Bregmanns gave rise to a new framework called auditory scene analysis. This proposed framwork could serve a fundamental modle of human auditory perception and, in contrast to earlyer approaches, could address questions of how humans are able to form a coherent and meangingful representation of the auditory world. Bregman suggests that the brain uses streaming and segregation to form auditory objects from spectro-temporal infromationen. 

Auditory scene analysis thereby relies on two different categories of grouping, called sequential and simultaneous integration. Simultaneous or vertical integration refers to the grouping of concurent properties into one or more separable auditory objects, a process informed by temporal cues like common onset and offset, spectral and spatial characteristics among others. Sequential integration on the other hand describes how temporally distinct sounds are merged into one or multiple coherently perceived stream (contrary to simulatinous grouping, only one such stream can be activly perceived at any time). While vertical and horizontal grouping can come to different and therefore competing results [@needsref], sequential grouping often takes precedence over cues for simulatoius integration [@needsref],.

When presented with a series of similiar or repeated auditory events, rare deviants (termed oddballs) result in a negative deflection of event-related responses measured with EEG. These alterations are indexed by the missmatch negativity (MMN) component obtained by subtracting the reponse to deviant events from the resposne to standard events. Negativity is strongest in the fronto-temporal area of the scalp with a peak latency ranging from 100 to 250 ms after stimulus onset. MMN components observed in magnetoencephalography (MEG) are called MMNm. 
There is a long line of reserach suggesting that MMN ist pre-attentive @ref. MMN has been tradionally described as an index of discrepancy between auditory input and the memory trace of the preceeding standard stimuli [@paavilainenMismatchnegativityMMNComponent2013a].nd as with first-order MMNs could sucesdully observed in infants [@heDevelopmentInfantMismatch2009]. 


A simmilar explaination can be offered in terms of predictive coding. Predictive coding is a biologically plausible model proposing prediction as the key feature of perception that was first descibed in the cortical visual system [@raoPredictiveCodingVisual1999]. Taking a broader view, predictive coding is part of a research tradition taking a probabilistic (or Baysian) approaches to brain function. Chharacterizing the brain as an *inference mashine*, this line of resoning traces back to Herman von Helmholtz's work in the late 19th century. In sharp contrast to traditional stimulis-driven models that describe the act of perception as a bottom-up process, in probabilistic terms, perception is not the direct result of sensory input, but is built by combining sensory input with predictions with internal, *probabilistic generative models*. Using prior knowledge abou the world, these models are assumed to constantly create probabilistic versions of exptected sensory input. Predictive coding more specifically suggests that at every processing state, predicitons and actual input is constanly compared and only their difference, called *prediciton error*, is propagated. Perception is thus seen as the process of improving the internal generative model by using sensory input to minimize prediciton error.  Because of that, predictive coding is sometimes casually reffered to as *controlled hallucination*. 

However, there are multiple in shortcoming in 

Precision weighting

### Hypothesis

As layed out above, we hypothize that that two possible rules cyrry predictive value: Firstly, the presentation ratio of A and B tones (9 to 1) can be used to make proportion-dependent predicitons as used in classcial oddball-paradigms. When tones are presented in a regular fashion, as it is the cas ein the predictable condition, the extracted pattern might also be used to predict the next tone. Thus, two plausible but concurent rules might guide predicitons in the *predictable* conditiion, while in the *random* codntion only the proportion-based regularity offers information to form predictions about upcoming tones. As has been shown before [@ref], pattern-based regulairites are commonly found to take precedence over proportion-based regularites. If this is indeed the case, B-tones in the *predictable* condtiion should not be considered a *missmatch* and thus should not elict a MMN. In contrast, since there is no way to predict B-tones in the *random* condition, these tones would be still considered as *deviant* events and therefore expcected to generate a MMN. Folowing this notion, one would also expect an expectation violation when predictable B-tones are replaced by A-tones, althpough they would be considered "standard" events when prediciton is purely guided by proportion.  This would be also in line with [@sussmanPredictabilityStimulusDeviance1998; @sussmanOrganizationSequentialSounds2005] interpretation of the original results. 



pattern regularity 

If the fixed order of the tones in the predictable state leads to a prediction of the B-tones, i.e. if the pattern regularity is extracted and the proportional regularity is irrelevant in the predictable context, we expect that the difference of predictable-BAAAAAA "B" and predictable-BAAA "A" is (significantly) less negative than the difference of random-BAAAAAA "B" minus random-BAAA "A". In addition, we assume that the difference of predictable-BAAAA "B" and predictable-BAAA "A" is not significantly different from zero, while the difference of random-BAAAAAA "B" and random-BAAA "A" is significantly less than zero. In addition, in the predictable state, the interruption of the pattern regularity with an A tone should produce a significant negativity. This means that the difference between predictable-BAAAA "A" and predictable-BAAA "A" is significantly more negative than the difference between random-BAAAA "A" and random-BAAA "A". In addition, we expect the difference between predictable-BAAAA "A" and predictable-BAAA "A" to be less than zero, while the difference between random-BAAAA "A" and random-BAAA "A" is not significantly different from zero. 


 , this process has been characterized as stimulis-driven 
 
  Predictive coding is a theoretical model based on in the fundamental idea that 
 
 In this model, these predictions are what is actually perceived while sensory information are 
 
- what are auditory objects?
- what influences their formation? 
- what is predicitve coding?
- how can objects be used for prediction?
- what happends when rules conflict?
- MMN and preidctive coding?


### Predictive Coding
- brain as inference machine

a. Auditory scene analysis 
b. Sussman et al.
c. Scharf & MÃ¼ller
d. 

\newpage