```{=tex}
\newpage
```
# Introduction

Unraveling the mysteries of human perception might be one of the most
fascinating and difficult challenges in cognitive sciences. We usually
have little regard for this, but at every single moment, we achieve
something outstanding: By forming a coherent representation from the
tangled mess of external stimuli that reach our sensory organs, we make
sense of the outside world. In doing so and seemingly effortlessly, we
overcome complicated mathematical and philosophical problems. Recent
advances in emerging fields like computer vision and machine hearing
have provided a sense of how daunting these tasks can be - requiring
complex models that consume vast amounts of computational resources and
energy. What enables the brain to fulfill these functions with such ease
while consuming no more than the power equivalent of a lightbulb?

Overy the centuries, many theories have been broad forward in an attempt
to answer these questions. While early philosophers like Aristotle
believed in the idea of direct or naïve realism (the idea that the
outside world is perceived directly), early modern scholars like John
Locke promoted the concept of indirect realism which is highly
compatible with the assumption of representationalism in cognitive
science (perceptual experiences result from an internal representation
rather than directy from outside objects). Among the first who developed
a consistent theory defining the rules followed by indirect perception
were the Gestalt psychologist of the early 20th century. Wertheimer,
Koffka, and Kühler hypothesized that Gestalt principles, self-organizing
rules on how individual elements should be grouped or separated, guide
perception. They based their principle on the observation that humans
perceive a global whole instead of just collections of individual parts.

Much later, auditory scientists faced the same challenges described in
the first paragraph, but now in a very particular context: They were
puzzled by the brain's ability to convert small fluctuations in air
pressure into actual auditory percepts. Somehow, the brain is forming
meaningful perceptual experiences from what can only be described as a
busy mess of sound waves that originate from a plethora of different
sources differing in pitch, loudness, and spatial position. Known as the
*cocktail party effect* [@cherryExperimentsRecognitionSpeech1953], this
problem was compared to inferring the positions, shapes, and movements
of motorboats on a lake - just by observing how two nearby objects move
up and down on the waves. Attempts to find answers to this perplexing
question lead to the development of auditory scene analysis (ASA). Not
unlike the concepts proposed by the Gestalt theorists six decades
earlier, [@bregman1990auditory] suggested that the brain uses so-called
*streaming* and *segregation* to form auditory objects from rich
spectro-temporal information. At its core, ASA relies on two different
categories of grouping, namely *sequential* and *simultaneous*
integration: Simultaneous integration (or vertical integration) refers
to the grouping of concurrent properties into one or more separable
auditory objects, a process informed by temporal cues like common onset
and offset, spectral and spatial characteristics. Sequential integration
(or horizontal integration), on the other hand, describes how temporally
distinct sounds are merged into one or multiple coherently perceived
streams (contrary to auditory objects in simultaneous grouping, only one
such stream can be actively perceived at any time). While vertical and
horizontal grouping can come to different and therefore competing
results, sequential grouping often takes precedence over cues for
simulations integration [@bendixenPredictabilityEffectsAuditory2014]

As is so often the case, the key to understanding such complex phenomena
seems to lie in learning about the most basic processing steps. In
auditory research, these steps usually come in the shape of very simple
stimuli, often consisting of nothing more than pure tones. Such stimuli
were also the first to be used in the auditory oddball paradigm, a now
well-established and robust paradigm extensively used in event-related
potential (ERP) studies [@squiresTwoVarietiesLonglatency1975]. In its
basic form, participants are presented with a series of similar tones or
sounds (so-called *standard* events), interrupted by rare tones or
sounds that differ in at least one feature (*deviant* events) from the
more frequent ones. Strikingly, deviant events elicit more extensive
neural activity over sensory areas. This finding that is known as the
mismatch negativity (MMN) component because when measured using EEG, a
robust negative deflection can be observed in the difference wave
obtained by subtracting the response to deviant events from the response
to standard events. Negativity is strongest in the frontotemporal area
of the scalp, with a peak latency ranging from 100 to 250 ms after
stimulus onset. The elicitation of an MMN is not restricted to the
repetition of physically identical stimuli but can also be observed when
deviant events are complex, e.g., when abstract auditory regularities
are violated [@paavilainenMismatchnegativityMMNComponent2013]. The
regularities can come in the form of relationships between two
[@saarinenRepresentationAbstractAttributes1992] or multiple tones
[@nordbyEventRelatedPotentialsBreaks1988; @schrogerPreattentivePeriodicityDetection1996; @alainBrainIndicesAutomatic1994].
Interestingly, this finding is also highly compatible with another
prevalent theory of perception, namely the idea that perception is not
(only) a stimulus-driven bottom-up process, but is informed by internal
predicitons of some kind. These kinds of ideas have been around a long
time and famously trace back to the physiologist Hermann von Helmholtz
but were also proposed by numerous other figures such as Richard
Gregory. In its most recent iteration, this theory has been known as
(hierarchical) predictive coding. Predictive coding specifically
suggests that at every processing state, predicitons from so-called
*probabilistic generative models* and sensory input are constanly
compared and only their difference, called the *prediciton error*, is
propagated. MMN responses have been proposed as an index of prediction
error [@wacongneEvidenceHierarchyPredictions2011]. Although other
interpetations exist [@mayMismatchNegativityMMN2010], MMNs are
frequently intepreted as markers of expectation violations stressing the
role predicitons play in perception [e.g.,
@winklerInterpretingMismatchNegativity2007].

An interesting situation arises when concurrent predictive clues exist.
Following this idea, @sussmanPredictabilityStimulusDeviance1998
presented participants with a sequence of frequent pure tones and rare
pitch deviants while reading a book of their choice. Tones were arranged
in a predictable five-tone pattern consisting of four standard tones and
one deviant (i.e., A-A-A-A-B-A-A-A-A-B, ''-'' indicating silence between
the tones). ERPs to A and B tones were compared for rapid (SOA of 100
ms) and slow (SOA of 1200 ms) stimulation rates. The 100 ms SOA
condition also included a control condition in which tone order was
pseudo-randomized (e.g., A-A-A-B-A-B-A-A-A) without altering deviant
probability ($p_B = 20\%$). When tones are presented randomly, only
their relative frequency of occurrence carries value for predicting the
pitch of the next tone. This, we refer to as *proportional regularity*.
However, in an ordered presentation, a sequence of four standard tones
is always followed by one deviant tone. Thus, understanding this
relationship should allow for *perfect prediction* in which all deviant
tones are expected with near-absolute certainty. We call this regularity
a *pattern regularity*. Provided the underlying mechanism can
incorporate such information, the processing of the pitch deviants
should correspond with that of standard tones, and therefore no MMN
would be elicited. Interestingly, in the case of Sussman et al., MMNs
were only elicited if tone presentation was slow and predictable or fast
and random, but not when predictable tones were presented in a rapid
fashion. In a subsequent study, @sussmanOrganizationSequentialSounds2005
used the same pattern at different SOAs (200 ms, 400 ms, and 800 ms).
Similar to their previous study, ordered presentation at 400 ms and 800
ms SOA elicited an MMN response, while at a stimulation rate of 200 ms,
evidence for such a deflection was absent. Sussman et al. attributed
this observation to sensory memory limitations. That is, only when
auditory memory can accommodate enough repetitions of the five-tone
pattern; the brain can integrate tones into a coherent representation
allowing for accurate predictions of deviant tones. This, in turn, would
explain the absence of MMNs in the fast presentation condition. Based on
this, they argued that while true for fast presentation rates with SOAs
up to 200 ms, for longer SOAs, pattern durations would be too long, and
thus representations would exceed sensory memory capacity.

In a recent in-class replication study,
@scharfPredictableChangesFastpacedinprep presented participants with the
same stimuli as Sussmann in a very similar experimental setting. Their
study only differed in that participants were given a simple task in
which they had to count visual targets instead of reading a book of
their choice. Surprisingly, while descriptive results were compatible
with those of Sussmann et al., pairwise comparisons revealed no
significant effect when comparing deviant and standard tones for both
the *random* and the *predictable* condition. Further Bayesian analysis
remained largely inconclusive, providing only *anecdotal* evidence in
favor of such an effect for *random* presentation and *moderate*
evidence for its absence in the *predictable* condition. In the face of
the replication crisis, many scientists have become painfully aware of
the importance of replicability [@ioannidisWhyMostPublished2005]. Exact
or quasi-exact replication studies that try to match the original
study's experimental conditions as closely as possible are regarded as
the gold standard of science
[@popperLogikForschungZur1935; @jasnyAgainAgainAgain2011]. However,
replications that extend, change, or optimize materials or methods of
the original work also offer valuable insight. This kind of replications
are known as conceptual [@schmidtShallWeReally2009] and refers to the
use of different methods to repeat the test of a hypothesis or
experimental result.

## Design and Hypothesises

This thesis soughs to replicate the findings by Sussman et al. It largly
follows the procure layed out by
@sussmanOrganizationSequentialSounds2005 though it deviates from the
original design in some important aspects First, afforementioned
five-tone patterns are not only presented in the *preictable* condition,
but also in the *random* context. That is, pseudo-random order will be
deberatly broken by occasionally presenting B-A-A-A-A-B-patterns. In
particular, this will make sure that the local history of B-tones in the
*random* condition is comparable to that in the *predictable* condition.
Secondly, B tones are compared exclusively with their preceding A tones.
And lastly, a small number of A-A-A-A-B will be replaced by A-A-A-A-A
sequences in both conditions aloowing the comparison of physically
identical tones in different contexts. The advantages of this design are
discussed in more detail in the following paragraphs. A pre-registration
coverng data collection, processing, and anaylis is avaible at
https://osf.io/cg2zd/. Deviations from this pre-specified plan and
further, exploratory analysisi will be clearly marked.

@sussmanOrganizationSequentialSounds2005 intepretation of the original
results would suggests that at fast stimultion rates, pattern-based
regulairites take precedence over proportion-based regularites. If this
is indeed the case, B-tones in the *predictable* condtiion should not be
considered a *missmatch* and thus should not elict an MMN. In contrast,
since there is no way to reliably predict B-tones in the *random*
condition, these tones would be still considered as *deviant* events and
are therefore expcected to generate a MMN. On the other hand, when a
predictable B tone is replced by an A tone, one would expect an MMN
altough tones are physically identical. Specifically, hypotheses are
formulated in regars to the ERPs elicted by the 5th tone in the
five-tone sequence (A-A-A-A-**B** or A-A-A-A-**A**) compared to the 4th
tone in that sequence (A-A-A-**A**-X, "X" marking either an A or an B
tone).

In summary, **if Sussman's interpeatation is indeed correct**, one
expects i) negativity in the N1/MMN time domain (about 100-200 ms after
the beginning of the tone) for deviations in the BAAAA*B* sequence in
the *random* condition, since B tones violate the *proportioanl
regularity*, ii) one expects no evidence for such an effect (or evidence
favoring $\mathcal{H_0}$ i.e. that there is no effect) in the
*predictable* context since more informative higher-order predictions
based on *pattern regularity* are not violated, and iii) the difference
waves should differ significantly. **If however no *pattern regularity*
is extracted**, B-tones should concotenly exlivt an MMN regardless of
presentation context since the predictive value of the *proportional
regularity* does not differ between conditions. In that case, difference
waves should not differ. As a third possiblity, **the brain might use
*proportional regularities* and *pattern regularities* concurently**,
resulting in a negativity following B-tones in either condition. To
further differentiate between these explainations, we also expect the
comparison of 5th A tones to peceedin A tones (A-A-A-**A**-X
vs. A-A-A-A-**A**) to elict a significant MMN for options i and iii, but
not for option ii.

```{=tex}
\newpage
```
# Methods and Materials

## Data Acquisition

### Participants

#### 100 ms Presentation Rate

Twenty-three psychology undergraduate students (2 males, average age
22.6 yrs., $SD=5.57$, range 18 - 42 yrs.) were recruited at the
Institute of Psychology at the University of Leipzig. All participants
reported good general health, normal hearing and had normal or
corrected-to-normal vision. Written informed consent was obtained before
the experiment. One-third (34.8%) of participants spent time enaging in
musical activities at time of survey, while 8.7% had no prior experience
in music training. Handedness was asseced using a modified version of
the Edinburgh Handedness Inventory
[@oldfieldAssessmentAnalysisHandedness1971, see appendix]. A majoritiy
(00%) of parcicipants favored the right hand. Particpants were blinded
in respect to the purpose of the experiment and received course credit
in compensation.

#### 150 ms Presentation Rate

Twenty healthy participants (0 males, average age 00.0 yrs., $SD=0.00$,
range 00 - 00 yrs.) were recruited. Particpants gave informed consent
and reported normal hearing and corrected or corrected-to-normal vision.
All participants were naive regarding the purpose of the experiment and
were compensated in cource credit or money. 00 participants (00%) had
received musical training in the last 5 years before the experiment
while 00 (00%) reported no musical experiance. In addition, participants
reported if streaming occured during the presentation of the tones.

### Stimuli and Stimulis Delivery

![Tones of two different frequencies (A=440 Hz, B=449 Hz) were presented
in two blocked conditions: In the "predictable" condition (top half),
tones followed a simple pattern in which a single B-tone followed four
A-tones. Some designated B-tones were replaced by A-tones ("pattern
deviants"). In the "random" condition (lower half), tones were presented
in a pseudo-random fashion ()](figures/fig_tones.pdf)

Participants where seated in a comfortable chair in a sound-insulated
cabin. The experimental setup was practically the same as the one used
ny Sussman, but instead of reading a book, subjects were asked to focus
their attention on a previously selected movie. Movies were presented
with subtitles but without sound. Commercially available software
(MATLAB R2014a; The MathWorks Inc, Natick, MA) in conjunction with the
Psychophysics Toolbox extension [version 3.0.12,
@brainardPsychophysicsToolbox1997; @kleinerWhatNewPsychtoolbox32007] was
used to control stimulus presentation. Stimuli consisted of pure
sinusoidal tones with a duration of 50 ms (including a 10 ms cosine
on/off ramp), presented isochronously at a stimulation onsets asynchrony
(SOA) of 100 ms for study 1 and 150 ms for study 2. Overall, a total of
40 blocks containing a mixture of frequent 440 Hz tones ("A" tones) and
infrequent 449 Hz tones ("B" tones) were delivered binaurally using
Sennheiser HD-25-1 II headphones. In one half of the blocks, tones were
presented in pseudo-random order (e.g. A-A-A-B-A-B-A}, "random"
condition), while in the remaining block tone presentation followed a
simple pattern in which a five-tone-sequence of four frequent tones and
one infrequent tone (i.e. A-A-A-A-B) was repeated cyclically
("predictable" condition). Block order was counterbalanced accross
participants. The ratio of frequent and infrequent tones was 10% for
both conditions. Within the predictable condition, 10% of designated
(infrequent) B tones were replaced by A tones, resulting in sporadic
five-tone sequences consisting solely of A tones (i.e. A-A-A-A-A), thus
violating the predictability rule. To assure comparability of local
histories between tones in both conditions, randomly arranged tones were
interspersed with sequences mimicking aforementioned patterns from the
predictable condition (B-A-A-A-A-B and B-A-A-A-A-A) in the random
condition. A grand total of 2000 tones in study 1 and 4000 tones in
study 2 were delivered to each participant.

### Data Acquisition

Electrophysiological data was recorded from active
silver-silver-chloride (*Ag*-*AgCl*) electrodes using an ActiveTwo
amplifier system (BioSemi B.V., Amsterdam, The Netherlands). Acquisition
was monitored online to ensure optimal data quality. A total of 39
channels were obtained using a 32-electrode-cap and 7 external
electrodes. Scalp electrode locations conformed to the international
10--20 system. Horizontal and vertical eye movement was obtained using
two bipolar configurations with electrodes placed around the lateral
canthi of the eyes and above and below the right eye. Additionally,
electrodes were placed on the tip of the nose and at the left and right
mastoid sites. Data was sampled at 512 Hz and on-line filtered at 1000
Hz.

## Analysis Pipeline

Data prepossessing was implemented using a custom pipeline based on the
*MNE Python* software package [@gramfortMEGEEGData2013] using *Python
3.7*. All computations were carried out on a cluster operated by the
University Computation Center of the University of Leipzig. Code used in
thesis is publicly available at
<https://github.com/marcpabst/xmas-oddballmatch>.

First, EEG data was subjected to the ZapLine procedure
[@decheveigneZapLineSimpleEffective2020] to remove line noise
contamination. A fivefold detection procedure as described by
@bigdely-shamloPREPPipelineStandardized2015 was then used to detect and
subsequently interpolate bad channels. This specifically included the
detection of channels thain contain prolonged segments with verry small
values (i.e. flat channels), the exclusion of channels based on robust
standard deviation (deviation criterion), unusualy pronounced
high-frequency noise (noisiness criterion), and the removal of channels
that were poorly predicted by nearby channels (correlation criterion and
predictability criterion). Channels considered bad by one or more of
these methods were removed and interpolated using spherical splines
[@perrinSphericalSplinesScalp1989]. Electrode locations for
interpolations were informed by the BESA Spherical Head Model.

For independant component anaylsis (ICA), a 1-Hz-high-pass filter (134th
order hamming-windowed FIR) was applied prior to ICA
[@winklerInfluenceHighpassFiltering2015]. To further reduce artifacts,
Artifact Subspace Reconstruction [ASR,
@mullenRealtimeNeuroimagingCognitive2015] was used to identify and
remove parts of the data with unusual characteristics (bursts). ICA was
then carried out using the *Picard* algorithm
[@ablinFasterICAOrthogonal2017; @ablinFasterIndependentComponent2018] on
PCA-whitened data. To avoid rank-deficiency when extracting components
from data with one or more interpolated channels, PCA was also used for
dimensionality reduction. The EEGLAB [version 2020.0,
@delormeEEGLABOpenSource2004] software package and the IClabel plugin
[version 1.2.6,
@pion-tonachiniICLabelAutomatedElectroencephalographic2019] were used to
automatically classify estimated components. Only components clearly
classified (i.e. confidence above 50%) as resulting from either eye
movement, muscular, or heartbeat activity were zeroed-out before
applying the mixing matrix to unfiltered data.

In line with recommendations from @widmannDigitalFilterDesign2015 and
@decheveigneFiltersWhenWhy2019, a ORDER finite impulse response (FIR)
bandpass filter from 0.1 Hz to 40 Hz (Hamming window, 0.1 Hz lower
bandwith, 4 Hz upper bandwidth, 0.0194 passband ripple, and 53 dB
stopband attenuation). Continuous data was epoched into 400 ms long
segments around stimulus onsets. Epochs included a 100 ms pre-stimulus
interval. No baseline correction was applied. Segments exeeding a
peak-to-peak voltage difference of 100 µV were removed. On average, NN
epochs No data set meet the pre-registrated exclusion criterion stated
of less than 100 trials per condition, thus data from all participants
(20 for 100 ms presentation rate and 23 for 150 ms presentation rate)
was analysed.

## Statistical Analysis

Statistical Analyis was carried out using the R programming language
(version 3.2). Dependent variables quantifying missmatch negativity
response were calculated by averaging amplitudes in a time window
strechting ±25 ms around the maximum negativity obtained by subtracting
the mean ERP timecourse following the A tones from the mean ERP
following B tones. To compute mean amplitudes, ERPs to 4th position A
tones (A-A-A-**A**-X, **boldface** indicates the tone of interest) and B
tones (A-A-A-A-**B**) were averaged seperatly for both the *random* and
the *predictable* *condition*. For the *random condition*, only tones
that were part of a sequence matching the patterns in the *predictable*
condition were included.

In accordance with the original analysis by
@sussmanOrganizationSequentialSounds2005, mean amplitudes for
frontocentral electrodes (FZ, F3, F4, FC1, and FC2) and the two mastoid
positions (M1 and M2) were averaged separately. Then, for both SOAs,
independant three-way repeated measures analyses of variance with
factors *condition* (factors *predcitable* and *random*), *stimulus
type* (factors *A tone* and *B tone*), *electrode locations* (levels
*fronto-central* and *mastoids*), and all possible interactions were
calculated. Following this, significant interactions effects were
further investigated using post-hoc *t*-tests.

Besides the fact that p-values are frequently misinterpreted
[@hubbardWidespreadMisinterpretationPvalues2011], traditional null
hypothesis testing fails to explicitly quantify evidence in favor of
$\mathcal{H_0}$ [e.g.
@aczelQuantifyingSupportNull2018; @meehlTheoreticalRisksTabular1978; @kirkPracticalSignificanceConcept1996; @goodmanDirtyDozenTwelve2008].
Similarly, p-values can exaggerate evidence against $\mathcal{H_0}$
[that is, observed data might be more likely under $\mathcal{H_0}$ than
under $\mathcal{H_1}$ even tough $\mathcal{H_0}$ is rejected e.g.,
@hubbardWhyValuesAre2008; @rouderBayesianTestsAccepting2009; @wagenmakersBayesianInferencePsychology2018; @sellkeCalibrationValuesTesting2001].[^1]
Conversely, Bayesian hypothesis testing using Bayes factors can provide
an intuitive way to compare observed data's likelihood under the null
hypothesis versus the alternative hypothesis
[@wagenmakersPracticalSolutionPervasive2007]:
$BF_{10} = \frac{Pr(data|\mathcal{H}_0)}{Pr(data|\mathcal{H}_1)}$. Here,
this approach was applied in agreement with the concept described by
@rouderBayesianTestsAccepting2009 as an alternative to classical
frequentist paired *t*-tests. Folowing this notion, Bayes factors for
within-participant differences $y_i$ were computed assuming
$\mathcal{H_0}: y_i \sim Normal(0, \sigma^2)$ and
$\mathcal{H_1}: y_i \sim Normal(\delta, \sigma^2)$;
$\delta \sim Cauchy(0, 1/\sqrt{2})$. A Jeffreys prior was used for the
variance $\sigma^2$ in both models: $p(\sigma^2) \propto 1/\sigma^2$.
Calculations were performed using the Hamiltonian Monte Carlo method
implemented in *Stan* [version 2.25,
@carpenterStanProbabilisticProgramming2017] and *RStan*
[@standevelopmentteamRStanInterfaceStan2020].

Finally, the relationship between epoch number and the reliability
analysis was analyzed by drawing random subsamples of different sizes
from both our data sets and calculating split-half reliability employing
the Spearman-Brown approach. For this, single trial responses for all A
and B tones in the predictable condition were randomly shuffled. Then,
$100, 200, ..., N_{max}$ ($N_{max, 100ms} = 3000, N_{max, 150ms}=1500$)
epoches were drawn, randomly assigned to one of two halfes, and
afterwards averaged seperatly for bothtone types. Then, split-half
realibility was calculated using the differences between A and B tones
in the MMN latency window using the Sprearman-Brown prophecy formula[^2]
[@brownEXPERIMENTALRESULTSCORRELATION1910; @spearmanCorrelationCalculatedFaulty1910].
This procedure was repeated 100 times for each $N$ and
split-half-relaibilites thus obtained were subsequently averaged.

```{=tex}
\newpage
```
# Results

![Figure 1: ERP grand averages (pooled FZ, F3, F4, FC1, and FC2
electrode locations) for an SOA of 100 ms (left) and 150 ms (right), for
A tones (A-A-A-**A**-X, blue dashed lines) and B tones (A-A-A-A-**B**,
orange dashed line) and their difference (B - A, green solid line).
Upper panels show ERPs for tones presented in a predcitable pattern
(*predcitable condition*) while lower panels show ERPs for tones
presented in pseudo-random order (*random condition*). Shaded area marks
MMN latency window (110 ms to 160 ms) used to calculate the distribution
of amplitude differences across particpants (middle of each panel) and
the difference of topographic maps averaged over the same interval
(right of each panel).](figures/fig_fronto.pdf){#fig:fronto}

Grand averages of event-related potentials (ERP) at pooled FZ, F3, F4,
FC1, and FC2 electrode locations to A tones (A-A-A-**A**-X), B tones
(A-A-A-A-**B**), and their difference (**B** tone minus **A** tone) are
displayed in fig. 1 for both 100 ms (left panel) and 150 ms (right
panel) stimulus onset asynchronies. The top half of each panel shows
ERPs in the *predictable condition* while the lower half depicts ERPs in
the *random condition*. For both presentation rates, clear rhythms
matching the presentation frequency of 10 Hz (100 ms) and respectively
6.667 Hz (150 ms) are seen as a result of substantial overlap of
neighbouring tones. Panels also show the distribution of mean amplitude
differences in the MMN latency window (as defined above, 110 ms to 160
ms after stimulus onset) across participants and the difference of scalp
topographies averaged over the same interval. Similarly, waveforms and
mean amplitude difference distributions at pooled mastoid sites are
shown in fig. 2.

![Figure 2: ERP grand averages (pooled M1, M2 electrode locations) for
an SOA of 100 ms (left) and 150 ms (right), for A tones (A-A-A-**A**-X,
blue dashed lines) and B tones (A-A-A-A-**B**, orange dashed line) and
their difference (B - A, green solid line). Upper panels show ERPs for
tones presented in a predcitable pattern (*predcitable condition*) while
lower panels show ERPs for tones presented in pseudo-random order
(*random condition*). Shaded area marks MMN latency window (110 ms to
160 ms) used to calculate the distribution of amplitude differences
across particpants.](figures/fig_mastoids.pdf){#fig:mastoids}

Evoked responses to A and B tones were compared by calculating mean
amplitudes in the MMN latency window and can be seen in Table 1. For the
100 ms SOA presentation, two-way repeated-measures analysis of variance
(ANOVA) results only revealed a significant effect of the interaction
term (*condition* x *stimulus type*; $F(1,19) = 16.75$, $p = 0.0006$)
for the frontocentral electrode cluster. For slower tone presentation
($SOA = 150 ms$ ), ANOVA results suggest a main effect of factor
*stimulus type* for both frontocentral ($F(1,22) = 0.03$, $p = 0.8680$))
and mastoid electrodes ($F(1,22) = 0.12$, $p = 0.7300$).

```{=latex}
\input{tables/anova_03_full.tex}
```
Post-hoc tests between ERPs to A and B tones were carried out using
two-tailed Student's *t*-tests complemenary Bayesian analysis comparing
A and B tones. P-values were corrected for multiple comparisons using
the Benjamini--Hochberg step-up procedure, Bayes factors were reported
in favor of the alternative hypothesis. Descriptively, mean amplitudes
at pooled frontocentral electrode locations were more negative for
randomly presented B tones than for randomly presented A tones,
regardless of tone presentation rate (100 ms:
$\Delta M = -0.358 \: \mu V$; 150 ms: $\Delta M = -0.555 \: \mu V$).
However, inference statistical analysis indicated a significant effect
only in the 150-ms condition ($t(22) = 3.28$, $p = .009$,
$CI_{.95} = [0.20,0.91]$; 100 ms: $t(19) = 1.64$, $p = .169$,
$CI_{.95} = [-0.10,0.81]$). A simmilar observation could be made for
predictable tones presented at 150 ms SOA ($\Delta M = -0.582 \: \mu V$,
$t(22) = 5.20$, $p < .001$, $CI_{.95} = [0.35,0.81]$), Strikingly
hoewever, when presented at 100 ms SOA, B tones elicited more positive
responses than A tones ($\Delta M = 0.383 \: \mu V$, $t(19) = -2.77$,
$p = .025$, $CI_{.95} = [-0.67,-0.09]$). Significantly more positive B
tones at at mastoids might indicate polarity reversal effects but were
only present at 150 ms SOA for predictable ($t(22) = -3.95$, $p = .003$,
$CI_{.95} = [-0.61,-0.19]$) tones but not for tones presented in random
order ($t(22) = -1.59$, $p = .169$, $CI_{.95} = [-1.18,0.16]$). No such
effect could be observed in the 100 ms SOA condition for either
predcitable ($t(19) = 1.09$, $p = .291$, $CI_{.95} = [-0.12,0.39]$) or
random presentation ($t(19) = -1.35$, $p = .219$,
$CI_{.95} = [-1.90,0.41]$).

![Averaged voltages in the MMN latency window for pooled frontocentral
and mastoid electrodes. Colored areas show sample probability density
function for A tones (green) and B tones (red). White diamonds indicate
estimated population mean, vertical bars represent 95%-conficence
interval. Only Benjamini-Hochberg-corrected p-values $< 0.05$ are
shown.](figures/fig_posthoc.pdf)

![Figure 3: ERP grand averages (pooled FZ, F3, F4, FC1, and FC2
electrode locations) for an SOA of 100 ms (left) and 150 ms (right), for
4th A tones (A-A-A-**A**-X, blue dashed lines) and 5th A tones
(A-A-A-A-**A**, orange dashed line) and their difference (B - A, green
solid line). Upper panels show ERPs for tones presented in a predcitable
pattern (*predcitable condition*) while lower panels show ERPs for tones
presented in pseudo-random order (*random condition*). Shaded area marks
MMN latency window (110 ms to 160 ms) used to calculate the distribution
of amplitude differences across particpants (middle of each panel) and
the difference of topographic maps averaged over the same interval
(right of each panel).](figures/fig_fronto2.pdf){#fig:fronto2}

To investigate whether absence of evidence for an MMN might be due to
low whin-participant sample sizes, the anaylsis was repeated for the
*random* condition including not only B tone trials that occured within
a five-tone sequence (as with the pregistrated analyis path), but all B
tones and their immediately preceding A tone. Results from this
comparison are shown in @Fig:??.

![Figure 4: EEG waveforms for five-tone sequences presented in an
predictable context (dotted line) and pseudo-random condition (dashed
line) for 100 ms presentation rate (top panel) and 150 ms presentation
rate (lower pabel). Vertical lines indicate tone
onset.](figures/fig_subsample_rel.pdf){#fig:rel}

Split-half reliabilities are displayed in fig. 4. Simulated values match
the curve expected from the Spearman-Brown formula. In the context of
classcial test theory, this method relates the length of a test (or
*experiment*) to the number of items (or *trials*). The first derivitve
of the Spearman-Brown function is monotonically decreasing, leading to
two different observation: i) Adding additional epochs (extending the
test length by an absolute value in classcial test theory terms) has a
large effect when the number of already present epochs is low, but has
only little effect when already dealing with large numbers of epochs and
ii) SOA and thus effect sized have a larger impact when epoch numbers
are small compared to high epoch numbers. Graphed values also show that
reliabilities for the 100 ms stimulation rate are considerably lower
than for an SOA of 150 ms and that reliabilities are very low when using
a relatively small number of epochs. There is no generally accepted rule
as to the level above which the coefficient can be considered
acceptable. Rather, reliabiliy should be evaluated based on the purpose
of a study considering the cost-benefit trade-off
[@nunnallyPsychometricTheory1994]. As laid out, inreased realibility
comes at overproportionate cost, in that collecting more samples will
not increase ralibility by the same factor. That said, many published
articles deem reliability coefficients above .7 or .8 "acceptable"
[@lanceSourcesFourCommonly2006].

```{=tex}
\newpage
```
# Discussion

For the 150 presentation, extreme evidence for an MMN and very strong
evidence for an accopying polarity reversal at the mastoids was found in
the *predcitable* condition, that is, when tones were presented in a
repeated five-tone pattern. When tones were presented in random order,
strong evidence was foun\[\[anova_02_100_posthoc\]\]
anova_02_100_posthoc.texd for an MMN but Bayes factors suggested
inconclusive evidence for mastoids. In light of the resuts by
@sussmanOrganizationSequentialSounds2005, we would

We found strong evidence for an MMN in the 150 ms delivery rate
condition when comparing standards and deviants, regardless of the type
of presentation (predictable vs. random). This finding is incompatible
with the results and intepretation by
[@sussmanOrganizationSequentialSounds2005] but suggests that *pattern
regularities* do not inform prediction. Furthermore, no convincing
evidence for an MMN was found when comparing the 4th standard to the 5th
standard in predictable condition.

For the 150 ms , significant MMN componets were found regardless of
presentation

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Donec id cursus
velit, non egestas quam. Aliquam rutrum eget sem ut aliquet. Etiam
euismod purus et gravida volutpat. Suspendisse consequat ipsum nibh,
vitae convallis dolor efficitur a. Suspendisse vehicula erat posuere
velit fermentum viverra. Proin sapien urna, iaculis ut ultricies ac,
auctor eu est. Nunc ornare pharetra finibus. Morbi finibus, ipsum non
accumsan cursus, metus nisl egestas leo, et aliquam nisi leo quis diam.
Quisque id diam non risus elementum convallis. Duis non nisl at nisl
imperdiet vestibulum. Suspendisse efficitur porttitor nulla a vehicula.
Interdum et malesuada fames ac ante ipsum primis in faucibus. Praesent
tempor urna in orci congue, non euismod eros volutpat. Integer
ullamcorper auctor libero, in laoreet nulla hendrerit ultrices.

Proin malesuada nisi et luctus volutpat. Nam ac posuere enim. Proin nec
augue tincidunt felis ullamcorper luctus ac sit amet mi. Maecenas
aliquam leo quis enim gravida maximus. Sed nec pellentesque magna.
Vivamus et purus lacus. Donec maximus purus at fermentum efficitur.
Phasellus auctor orci sem, eu sollicitudin eros pretium a.

In maximus libero at purus lobortis efficitur. Aliquam nec sapien
consequat, lobortis lorem id, luctus velit. Pellentesque habitant morbi
tristique senectus et netus et malesuada fames ac turpis egestas.
Vestibulum dictum ipsum eu nunc maximus, quis ornare augue tincidunt.
Nam leo purus, mollis quis nunc sed, sagittis tempus orci. In
condimentum et neque ut laoreet. Curabitur accumsan ligula eu libero
iaculis ullamcorper. Interdum et malesuada fames ac ante ipsum primis in
faucibus. Nullam iaculis tellus risus, vitae dapibus augue commodo a.
Sed ante dolor, fermentum at lectus id, pulvinar viverra elit. Aenean
tincidunt mollis imperdiet.

Nulla id molestie neque, vitae vulputate velit. Fusce a velit imperdiet
felis porttitor scelerisque. Nam tempus tincidunt elit, id finibus
tortor tristique non. Ut imperdiet finibus mauris, in fringilla mauris
blandit auctor. Etiam volutpat quam et feugiat elementum. Duis finibus
fermentum condimentum. Donec sollicitudin molestie dolor. Cras convallis
lorem orci, ut sagittis risus rutrum eget. Donec vel lobortis justo.

Pellentesque habitant morbi tristique senectus et netus et malesuada
fames ac turpis egestas. Proin non leo vehicula, congue elit faucibus,
tincidunt diam. Sed euismod vulputate mauris. Duis dapibus faucibus
arcu, ut vehicula tellus blandit eu. Duis erat magna, cursus quis urna
nec, placerat blandit lectus. Maecenas dolor quam, pharetra a urna eu,
mollis iaculis dolor. Aliquam maximus ante eget felis faucibus porta.
Cras semper felis non tellus rutrum tempus. Morbi quam metus, volutpat
nec aliquam at, interdum a nibh. Sed hendrerit purus tempor ex placerat,
ut fringilla nulla molestie. Nullam vitae sem non purus lobortis
fermentum. Quisque ligula tellus, ullamcorper sit amet consectetur quis,
fermentum ac mi. Nunc pretium mollis dictum. `\newpage`{=tex} \#
References

[^1]: it doesn't quantify evidence in favor of the $\mathcal{H_1}$,
    either

[^2]: as given by ${\rho}_{xx'} = \frac{2{\rho}_{12}}{1+{\rho}_{12}}$,
    where ${\rho_{12}}$ is the Pearson correlation coefficient between
    the two halfes.
